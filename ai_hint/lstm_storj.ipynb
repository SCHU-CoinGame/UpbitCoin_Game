{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-29 10:57:53.688553: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-29 10:57:53.847599: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-29 10:57:53.853510: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
      "2024-10-29 10:57:53.853536: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-10-29 10:57:54.619811: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
      "2024-10-29 10:57:54.619888: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
      "2024-10-29 10:57:54.619895: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "import joblib\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import pyupbit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "coins = ['KRW-STORJ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(coins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = 'minute1'\n",
    "count = 3126000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestep = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-29 10:57:59.588511: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
      "2024-10-29 10:57:59.588613: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
      "2024-10-29 10:57:59.588688: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
      "2024-10-29 10:57:59.591485: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
      "2024-10-29 10:57:59.591571: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
      "2024-10-29 10:57:59.591647: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
      "2024-10-29 10:57:59.591661: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-10-29 10:57:59.592293: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(50, return_sequences=True, input_shape=(timestep, 1)))\n",
    "model.add(LSTM(50, return_sequences=False))\n",
    "model.add(Dense(25))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KRW-STORJ model does not exist\n",
      "KRW-STORJ data loaded\n",
      "KRW-STORJ train start\n"
     ]
    }
   ],
   "source": [
    "for ticker in coins:\n",
    "    if os.path.exists(f'models/lstm_{ticker}.h5'):\n",
    "        print(f'{ticker} model already exists')\n",
    "        continue\n",
    "    else:\n",
    "        print(f'{ticker} model does not exist')\n",
    "    \n",
    "    if not os.path.exists(f'../data/from_pyupbit/{ticker}.csv'):\n",
    "        now = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        df = pyupbit.get_ohlcv(ticker, interval=interval, count=count).reset_index().rename(columns={'index': 'timestamp'})\n",
    "        df.to_csv(f'../data/from_pyupbit/{ticker}.csv', index=False)\n",
    "    else:\n",
    "        df = pd.read_csv(f'../data/from_pyupbit/{ticker}.csv')\n",
    "        \n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    df.set_index('timestamp', inplace=True)\n",
    "        \n",
    "    print(f'{ticker} data loaded')\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data = scaler.fit_transform(df['close'].values.reshape(-1, 1))\n",
    "    joblib.dump(scaler, f'models/{ticker}_scaler.pkl')\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(scaled_data) - timestep - 1):\n",
    "        X.append(scaled_data[i:(i + timestep), 0])\n",
    "        y.append(scaled_data[i + timestep, 0])\n",
    "    \n",
    "    X, y = np.array(X), np.array(y)\n",
    "    \n",
    "    train_size = int(len(X) * .8)\n",
    "    X_train, X_test = X[:train_size], X[train_size:]\n",
    "    y_train, y_test = y[:train_size], y[train_size:]\n",
    "    \n",
    "    train_dates = df.index[:train_size]\n",
    "    test_dates = df.index[train_size:]\n",
    "    \n",
    "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    \n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=10)\n",
    "    \n",
    "    print(f'{ticker} train start')\n",
    "    \n",
    "    model.fit(X_train, y_train, batch_size=32, epochs=20,\n",
    "          validation_data=(X_test, y_test), callbacks=[early_stop], verbose=0)\n",
    "    \n",
    "    model.save(f'models/lstm_{ticker}.h5')\n",
    "    \n",
    "    train_predict = model.predict(X_train)\n",
    "    test_predict = model.predict(X_test)\n",
    "    \n",
    "    train_predict = scaler.inverse_transform(train_predict)\n",
    "    test_predict = scaler.inverse_transform(test_predict)\n",
    "    y_train = scaler.inverse_transform([y_train])\n",
    "    y_test = scaler.inverse_transform([y_test])\n",
    "    \n",
    "    train_score = np.sqrt(mean_squared_error(y_train[0], train_predict[:, 0]))\n",
    "    test_score = np.sqrt(mean_squared_error(y_test[0], test_predict[:, 0]))\n",
    "    print(f'{ticker} Train RMSE: {train_score:.6f} Test RMSE: {test_score:.6f}')\n",
    "    \n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.subplot(1, 1, 1)\n",
    "    plt.plot(train_dates, y_train[0], label='Actual', color = 'Blue')\n",
    "    plt.plot(train_dates, train_predict, label='Predicted', color = 'Red')\n",
    "    plt.title('Train Data')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Price')\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.gca().xaxis.set_major_formatter(DateFormatter('%Y'))\n",
    "    plt.savefig(f'results/{ticker}_train.png')\n",
    "    \n",
    "    plt.subplot(1, 1, 1)\n",
    "    plt.plot(test_dates[:-2], y_test[0], label='Actual', color = 'Blue')\n",
    "    plt.plot(test_dates[:-2], test_predict, label='Predicted', color = 'Red')\n",
    "    plt.title('Test Data')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Price')\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.gca().xaxis.set_major_formatter(DateFormatter('%Y-%m'))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'results/{ticker}_test.png')\n",
    "    \n",
    "    last_1_day = scaled_data[-timestep:]\n",
    "    X_predict = last_1_day.reshape(1, timestep, 1)\n",
    "    pred = model.predict(X_predict)\n",
    "    pred = scaler.inverse_transform(pred)\n",
    "    print(f'{ticker} Actual {scaler.inverse_transform(last_1_day)} Pred', pred)\n",
    "    \n",
    "    preds = []\n",
    "    for i in range(30):\n",
    "        pred = model.predict(X_predict, verbose=0)\n",
    "        preds.append(scaler.inverse_transform(pred)[0][0])\n",
    "        pred = pred.reshape(1, 1, 1)\n",
    "        X_predict = np.append(X_predict[:, 1:, :], pred, axis=1).reshape(1, timestep, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KRW-STORJ data loaded\n",
      "KRW-STORJ train start\n"
     ]
    }
   ],
   "source": [
    "for ticker in coins:\n",
    "    df = pd.read_csv(f'../data/from_pyupbit/{ticker}.csv')\n",
    "        \n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    df.set_index('timestamp', inplace=True)\n",
    "        \n",
    "    print(f'{ticker} data loaded')\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data = scaler.fit_transform(df['close'].values.reshape(-1, 1))\n",
    "    joblib.dump(scaler, f'models/{ticker}_scaler.pkl')\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(scaled_data) - timestep - 1):\n",
    "        X.append(scaled_data[i:(i + timestep), 0])\n",
    "        y.append(scaled_data[i + timestep, 0])\n",
    "    \n",
    "    X, y = np.array(X), np.array(y)\n",
    "    \n",
    "    train_size = int(len(X) * .8)\n",
    "    X_train, X_test = X[:train_size], X[train_size:]\n",
    "    y_train, y_test = y[:train_size], y[train_size:]\n",
    "    \n",
    "    train_dates = df.index[:train_size]\n",
    "    test_dates = df.index[train_size:]\n",
    "    \n",
    "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    \n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=10)\n",
    "    \n",
    "    print(f'{ticker} train start')\n",
    "    \n",
    "    model.fit(X_train, y_train, batch_size=32, epochs=20,\n",
    "          validation_data=(X_test, y_test), callbacks=[early_stop], verbose=0)\n",
    "    \n",
    "    model.save(f'models/lstm_{ticker}.h5')\n",
    "    \n",
    "    train_predict = model.predict(X_train)\n",
    "    test_predict = model.predict(X_test)\n",
    "    \n",
    "    train_predict = scaler.inverse_transform(train_predict)\n",
    "    test_predict = scaler.inverse_transform(test_predict)\n",
    "    y_train = scaler.inverse_transform([y_train])\n",
    "    y_test = scaler.inverse_transform([y_test])\n",
    "    \n",
    "    train_score = np.sqrt(mean_squared_error(y_train[0], train_predict[:, 0]))\n",
    "    test_score = np.sqrt(mean_squared_error(y_test[0], test_predict[:, 0]))\n",
    "    print(f'{ticker} Train RMSE: {train_score:.6f} Test RMSE: {test_score:.6f}')\n",
    "    \n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.subplot(1, 1, 1)\n",
    "    plt.plot(train_dates, y_train[0], label='Actual', color = 'Blue')\n",
    "    plt.plot(train_dates, train_predict, label='Predicted', color = 'Red')\n",
    "    plt.title('Train Data')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Price')\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.gca().xaxis.set_major_formatter(DateFormatter('%Y'))\n",
    "    plt.savefig(f'results/{ticker}_train.png')\n",
    "    \n",
    "    plt.subplot(1, 1, 1)\n",
    "    plt.plot(test_dates[:-2], y_test[0], label='Actual', color = 'Blue')\n",
    "    plt.plot(test_dates[:-2], test_predict, label='Predicted', color = 'Red')\n",
    "    plt.title('Test Data')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Price')\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.gca().xaxis.set_major_formatter(DateFormatter('%Y-%m'))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'results/{ticker}_test.png')\n",
    "    \n",
    "    last_1_day = scaled_data[-timestep:]\n",
    "    X_predict = last_1_day.reshape(1, timestep, 1)\n",
    "    pred = model.predict(X_predict)\n",
    "    pred = scaler.inverse_transform(pred)\n",
    "    print(f'{ticker} Actual {scaler.inverse_transform(last_1_day)} Pred', pred)\n",
    "    \n",
    "    preds = []\n",
    "    for i in range(30):\n",
    "        pred = model.predict(X_predict, verbose=0)\n",
    "        preds.append(scaler.inverse_transform(pred)[0][0])\n",
    "        pred = pred.reshape(1, 1, 1)\n",
    "        X_predict = np.append(X_predict[:, 1:, :], pred, axis=1).reshape(1, timestep, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
